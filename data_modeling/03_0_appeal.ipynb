{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(os.path.dirname(os.getcwd()), 'xlsx_data', f\"{'xlsx_#10_final'}.xlsx\")\n",
    "cname = os.path.join(os.path.dirname(os.getcwd()), 'xlsx_data', f\"{'xlsx_#10_case'}.xlsx\")\n",
    "lname = os.path.join(os.path.dirname(os.getcwd()), 'xlsx_data', f\"{'xlsx_#10_law'}.xlsx\")\n",
    "\n",
    "dff = pd.read_excel(fname, index_col=0)\n",
    "dfc = pd.read_excel(cname, index_col=0)\n",
    "dfl = pd.read_excel(lname, index_col=0)\n",
    "\n",
    "df = pd.concat([dff[['text', 'y_appeal']], dfc[1:], dfl[1:]], axis=1).reindex(dff.index)\n",
    "df = df.dropna(subset=['y_appeal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['y_appeal'] == 0].sample(frac=1)\n",
    "df_1 = df[df['y_appeal'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(df_0) if len(df_0) < len(df_1) else len(df_1)\n",
    "\n",
    "df = pd.concat([df_0.head(sample_size), df_1.head(sample_size)]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y_appeal', axis=1)\n",
    "y = tf.keras.utils.to_categorical(df['y_appeal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train[dfc.columns[1:]]\n",
    "X1_test = X_test[dfc.columns[1:]]\n",
    "\n",
    "X2_train = X_train[dfl.columns[1:]]\n",
    "X2_test = X_test[dfl.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = list(X_train[\"text\"])\n",
    "X3_test = list(X_test[\"text\"])\n",
    "\n",
    "max_features = 30000\n",
    "sequence_length = 256\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\n",
    "tokenizer.fit_on_texts(X3_train)\n",
    "\n",
    "X3_train = tokenizer.texts_to_sequences(X3_train)\n",
    "X3_test = tokenizer.texts_to_sequences(X3_test)\n",
    "\n",
    "X3_train = tf.keras.preprocessing.sequence.pad_sequences(X3_train, sequence_length)\n",
    "X3_test = tf.keras.preprocessing.sequence.pad_sequences(X3_test, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = tf.keras.Input(dtype = tf.float32, shape = (len(dfc.columns[1:]),))\n",
    "input_2 = tf.keras.Input(dtype = tf.float32, shape = (len(dfl.columns[1:]),))\n",
    "\n",
    "dense_layer_1_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_1)\n",
    "dense_layer_1_2 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_1)\n",
    "dense_layer_1_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_2)\n",
    "dense_layer_1_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_3)\n",
    "dropout_1_5 = tf.keras.layers.Dropout(rate = 0.5)(dense_layer_1_4)\n",
    "\n",
    "\n",
    "dense_layer_2_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_2)\n",
    "dense_layer_2_2 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_2_1)\n",
    "dense_layer_2_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_2_2)\n",
    "dense_layer_2_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_2_3)\n",
    "dropout_2_5 = tf.keras.layers.Dropout(rate = 0.5)(dense_layer_2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13510\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(os.path.dirname(os.getcwd()), 'data_processing', 'ft_0825_6.txt'),  encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "num_words = min(max_features, len(word_index)) + 1\n",
    "print(num_words)\n",
    "embedding_dim = 200\n",
    "num_filters = 100\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3 = tf.keras.Input(dtype = tf.float32, shape = (sequence_length,))\n",
    "embedding_layer_3 = tf.keras.layers.Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=True)(input_3)\n",
    "\n",
    "reshape_3 = tf.keras.layers.Reshape((sequence_length, embedding_dim, 1))(embedding_layer_3)\n",
    "\n",
    "conv_0_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(3, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "conv_1_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(4, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "conv_2_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(5, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "\n",
    "maxpool_0_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_3)\n",
    "maxpool_1_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_3)\n",
    "maxpool_2_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_3)\n",
    "\n",
    "concatenated_tensor_3 = tf.keras.layers.Concatenate(axis=1)([maxpool_0_3, maxpool_1_3, maxpool_2_3])\n",
    "flatten_3 = tf.keras.layers.Flatten()(concatenated_tensor_3)\n",
    "dropout_3 = tf.keras.layers.Dropout(rate = 0.5)(flatten_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_layer = tf.keras.layers.Concatenate()([dropout_1_5, dropout_2_5, dropout_3])\n",
    "\n",
    "dense_layer_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(concat_layer)\n",
    "dense_layer_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_3)\n",
    "dense_layer_5 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_4)\n",
    "dense_layer_6 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_5)\n",
    "\n",
    "\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax)(dense_layer_3)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_1, input_2, input_3], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 256, 200)     2702000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 153)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 567)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 256, 200, 1)  0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           1540        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           5680        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 254, 1, 100)  60100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 253, 1, 100)  80100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 252, 1, 100)  100100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           110         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 100)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           110         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           110         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 1, 100)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           110         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 300)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           3210        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           110         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            22          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,953,522\n",
      "Trainable params: 2,953,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 864 samples, validate on 97 samples\n",
      "Epoch 1/100\n",
      "864/864 [==============================] - 4s 5ms/sample - loss: 14.6570 - acc: 0.5174 - val_loss: 11.2907 - val_acc: 0.4536\n",
      "Epoch 2/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 8.9781 - acc: 0.5347 - val_loss: 6.9952 - val_acc: 0.6495\n",
      "Epoch 3/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 5.6169 - acc: 0.5648 - val_loss: 4.4523 - val_acc: 0.6804\n",
      "Epoch 4/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 3.6263 - acc: 0.5775 - val_loss: 2.9367 - val_acc: 0.7113\n",
      "Epoch 5/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 2.4366 - acc: 0.6157 - val_loss: 2.0258 - val_acc: 0.6804\n",
      "Epoch 6/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 1.7149 - acc: 0.6250 - val_loss: 1.4728 - val_acc: 0.4845\n",
      "Epoch 7/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 1.2731 - acc: 0.6389 - val_loss: 1.1240 - val_acc: 0.6907\n",
      "Epoch 8/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 1.0014 - acc: 0.7095 - val_loss: 0.9197 - val_acc: 0.7629\n",
      "Epoch 9/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.8384 - acc: 0.7743 - val_loss: 0.7928 - val_acc: 0.7938\n",
      "Epoch 10/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.7388 - acc: 0.7917 - val_loss: 0.7053 - val_acc: 0.7938\n",
      "Epoch 11/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.6730 - acc: 0.8310 - val_loss: 0.6470 - val_acc: 0.8660\n",
      "Epoch 12/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.6302 - acc: 0.8588 - val_loss: 0.6005 - val_acc: 0.8660\n",
      "Epoch 13/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5887 - acc: 0.8843 - val_loss: 0.5716 - val_acc: 0.8351\n",
      "Epoch 14/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5746 - acc: 0.8773 - val_loss: 0.5557 - val_acc: 0.8763\n",
      "Epoch 15/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5627 - acc: 0.8738 - val_loss: 0.5416 - val_acc: 0.8557\n",
      "Epoch 16/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5403 - acc: 0.8981 - val_loss: 0.5317 - val_acc: 0.8454\n",
      "Epoch 17/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5386 - acc: 0.8947 - val_loss: 0.5295 - val_acc: 0.8660\n",
      "Epoch 18/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5291 - acc: 0.8935 - val_loss: 0.5206 - val_acc: 0.8454\n",
      "Epoch 19/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5212 - acc: 0.9062 - val_loss: 0.5159 - val_acc: 0.8557\n",
      "Epoch 20/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.5196 - acc: 0.9109 - val_loss: 0.5108 - val_acc: 0.8454\n",
      "Epoch 21/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4995 - acc: 0.9213 - val_loss: 0.5030 - val_acc: 0.8557\n",
      "Epoch 22/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4988 - acc: 0.9236 - val_loss: 0.4962 - val_acc: 0.8660\n",
      "Epoch 23/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4815 - acc: 0.9306 - val_loss: 0.4951 - val_acc: 0.8660\n",
      "Epoch 24/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4869 - acc: 0.9294 - val_loss: 0.4962 - val_acc: 0.8247\n",
      "Epoch 25/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4875 - acc: 0.9248 - val_loss: 0.4972 - val_acc: 0.8660\n",
      "Epoch 26/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4662 - acc: 0.9433 - val_loss: 0.4904 - val_acc: 0.8351\n",
      "Epoch 27/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4672 - acc: 0.9317 - val_loss: 0.4919 - val_acc: 0.8454\n",
      "Epoch 28/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4713 - acc: 0.9340 - val_loss: 0.4848 - val_acc: 0.8557\n",
      "Epoch 29/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4651 - acc: 0.9456 - val_loss: 0.4893 - val_acc: 0.8557\n",
      "Epoch 30/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4589 - acc: 0.9514 - val_loss: 0.4830 - val_acc: 0.8660\n",
      "Epoch 31/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4488 - acc: 0.9444 - val_loss: 0.4794 - val_acc: 0.8763\n",
      "Epoch 32/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4505 - acc: 0.9468 - val_loss: 0.4760 - val_acc: 0.8660\n",
      "Epoch 33/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4506 - acc: 0.9375 - val_loss: 0.4745 - val_acc: 0.8454\n",
      "Epoch 34/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4467 - acc: 0.9456 - val_loss: 0.4760 - val_acc: 0.8660\n",
      "Epoch 35/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4416 - acc: 0.9537 - val_loss: 0.4694 - val_acc: 0.8763\n",
      "Epoch 36/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4367 - acc: 0.9421 - val_loss: 0.4742 - val_acc: 0.8557\n",
      "Epoch 37/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4323 - acc: 0.9514 - val_loss: 0.4738 - val_acc: 0.8969\n",
      "Epoch 38/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4186 - acc: 0.9641 - val_loss: 0.4651 - val_acc: 0.8660\n",
      "Epoch 39/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4303 - acc: 0.9491 - val_loss: 0.4688 - val_acc: 0.8866\n",
      "Epoch 40/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4114 - acc: 0.9549 - val_loss: 0.4591 - val_acc: 0.8660\n",
      "Epoch 41/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4129 - acc: 0.9549 - val_loss: 0.4706 - val_acc: 0.8454\n",
      "Epoch 42/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4265 - acc: 0.9421 - val_loss: 0.4646 - val_acc: 0.8763\n",
      "Epoch 43/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4218 - acc: 0.9444 - val_loss: 0.4659 - val_acc: 0.8763\n",
      "Epoch 44/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4226 - acc: 0.9433 - val_loss: 0.4716 - val_acc: 0.8866\n",
      "Epoch 45/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4115 - acc: 0.9641 - val_loss: 0.4617 - val_acc: 0.8763\n",
      "Epoch 46/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4040 - acc: 0.9560 - val_loss: 0.4658 - val_acc: 0.8454\n",
      "Epoch 47/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3950 - acc: 0.9618 - val_loss: 0.4665 - val_acc: 0.8660\n",
      "Epoch 48/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4064 - acc: 0.9468 - val_loss: 0.4789 - val_acc: 0.8557\n",
      "Epoch 49/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.4015 - acc: 0.9583 - val_loss: 0.4652 - val_acc: 0.8866\n",
      "Epoch 50/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.4048 - acc: 0.9606 - val_loss: 0.4710 - val_acc: 0.8247\n",
      "Epoch 51/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3945 - acc: 0.9583 - val_loss: 0.4599 - val_acc: 0.8969\n",
      "Epoch 52/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3917 - acc: 0.9606 - val_loss: 0.4593 - val_acc: 0.8763\n",
      "Epoch 53/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3898 - acc: 0.9641 - val_loss: 0.4687 - val_acc: 0.8454\n",
      "Epoch 54/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3957 - acc: 0.9514 - val_loss: 0.4760 - val_acc: 0.8557\n",
      "Epoch 55/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3860 - acc: 0.9653 - val_loss: 0.4532 - val_acc: 0.8660\n",
      "Epoch 56/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3781 - acc: 0.9618 - val_loss: 0.4498 - val_acc: 0.8763\n",
      "Epoch 57/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3991 - acc: 0.9491 - val_loss: 0.4749 - val_acc: 0.8247\n",
      "Epoch 58/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3796 - acc: 0.9572 - val_loss: 0.4616 - val_acc: 0.8660\n",
      "Epoch 59/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.4000 - acc: 0.9491 - val_loss: 0.4880 - val_acc: 0.8351\n",
      "Epoch 60/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3830 - acc: 0.9676 - val_loss: 0.4569 - val_acc: 0.8969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3722 - acc: 0.9722 - val_loss: 0.4563 - val_acc: 0.8969\n",
      "Epoch 62/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3773 - acc: 0.9618 - val_loss: 0.4523 - val_acc: 0.8969\n",
      "Epoch 63/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3698 - acc: 0.9653 - val_loss: 0.4781 - val_acc: 0.8454\n",
      "Epoch 64/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3789 - acc: 0.9572 - val_loss: 0.4646 - val_acc: 0.8454\n",
      "Epoch 65/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3943 - acc: 0.9525 - val_loss: 0.4933 - val_acc: 0.8557\n",
      "Epoch 66/100\n",
      "864/864 [==============================] - 2s 3ms/sample - loss: 0.3672 - acc: 0.9745 - val_loss: 0.4769 - val_acc: 0.8351\n",
      "Epoch 67/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3679 - acc: 0.9653 - val_loss: 0.4589 - val_acc: 0.8866\n",
      "Epoch 68/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3672 - acc: 0.9641 - val_loss: 0.4651 - val_acc: 0.8660\n",
      "Epoch 69/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3741 - acc: 0.9618 - val_loss: 0.4658 - val_acc: 0.8866\n",
      "Epoch 70/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3627 - acc: 0.9722 - val_loss: 0.4498 - val_acc: 0.8866\n",
      "Epoch 71/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3699 - acc: 0.9699 - val_loss: 0.4571 - val_acc: 0.8866\n",
      "Epoch 72/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3823 - acc: 0.9549 - val_loss: 0.4578 - val_acc: 0.8969\n",
      "Epoch 73/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3737 - acc: 0.9664 - val_loss: 0.4474 - val_acc: 0.8969\n",
      "Epoch 74/100\n",
      "864/864 [==============================] - 2s 2ms/sample - loss: 0.3733 - acc: 0.9595 - val_loss: 0.4672 - val_acc: 0.8660\n",
      "Epoch 75/100\n",
      "480/864 [===============>..............] - ETA: 0s - loss: 0.3751 - acc: 0.9729"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X1_train, X2_train, X3_train], y=y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x=[X1_test, X2_test, X3_test], y=y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test ACC:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
