{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-14 15:33:51,252 : INFO : resetting layer weights\n",
      "2020-08-14 15:33:56,132 : INFO : collecting all words and their counts\n",
      "2020-08-14 15:33:56,133 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-14 15:33:56,174 : INFO : PROGRESS: at sentence #10000, processed 117494 words, keeping 8898 word types\n",
      "2020-08-14 15:33:56,212 : INFO : PROGRESS: at sentence #20000, processed 241152 words, keeping 12390 word types\n",
      "2020-08-14 15:33:56,249 : INFO : PROGRESS: at sentence #30000, processed 361153 words, keeping 15126 word types\n",
      "2020-08-14 15:33:56,284 : INFO : PROGRESS: at sentence #40000, processed 479225 words, keeping 17207 word types\n",
      "2020-08-14 15:33:56,320 : INFO : PROGRESS: at sentence #50000, processed 595092 words, keeping 19437 word types\n",
      "2020-08-14 15:33:56,358 : INFO : PROGRESS: at sentence #60000, processed 714109 words, keeping 21234 word types\n",
      "2020-08-14 15:33:56,392 : INFO : PROGRESS: at sentence #70000, processed 830101 words, keeping 22976 word types\n",
      "2020-08-14 15:33:56,426 : INFO : PROGRESS: at sentence #80000, processed 943878 words, keeping 24536 word types\n",
      "2020-08-14 15:33:56,463 : INFO : PROGRESS: at sentence #90000, processed 1060833 words, keeping 26014 word types\n",
      "2020-08-14 15:33:56,503 : INFO : PROGRESS: at sentence #100000, processed 1193194 words, keeping 27713 word types\n",
      "2020-08-14 15:33:56,543 : INFO : PROGRESS: at sentence #110000, processed 1318430 words, keeping 29240 word types\n",
      "2020-08-14 15:33:56,582 : INFO : PROGRESS: at sentence #120000, processed 1445988 words, keeping 31008 word types\n",
      "2020-08-14 15:33:56,619 : INFO : PROGRESS: at sentence #130000, processed 1573983 words, keeping 32467 word types\n",
      "2020-08-14 15:33:56,658 : INFO : PROGRESS: at sentence #140000, processed 1700699 words, keeping 33929 word types\n",
      "2020-08-14 15:33:56,696 : INFO : PROGRESS: at sentence #150000, processed 1838756 words, keeping 35274 word types\n",
      "2020-08-14 15:33:56,741 : INFO : PROGRESS: at sentence #160000, processed 1991879 words, keeping 36548 word types\n",
      "2020-08-14 15:33:56,758 : INFO : collected 37166 word types from a corpus of 2052549 raw words and 164073 sentences\n",
      "2020-08-14 15:33:56,759 : INFO : Loading a fresh vocabulary\n",
      "2020-08-14 15:33:56,788 : INFO : effective_min_count=5 retains 15061 unique words (40% of original 37166, drops 22105)\n",
      "2020-08-14 15:33:56,789 : INFO : effective_min_count=5 leaves 2016008 word corpus (98% of original 2052549, drops 36541)\n",
      "2020-08-14 15:33:56,823 : INFO : deleting the raw counts dictionary of 37166 items\n",
      "2020-08-14 15:33:56,825 : INFO : sample=0.001 downsamples 6 most-common words\n",
      "2020-08-14 15:33:56,825 : INFO : downsampling leaves estimated 2000055 word corpus (99.2% of prior 2016008)\n",
      "2020-08-14 15:33:56,890 : INFO : estimated required memory for 15061 words, 58432 buckets and 128 dimensions: 54129172 bytes\n",
      "2020-08-14 15:33:56,892 : INFO : resetting layer weights\n",
      "2020-08-14 15:34:01,767 : INFO : training model with 3 workers on 15061 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-14 15:34:03,826 : INFO : EPOCH 1 - PROGRESS: at 37.00% examples, 330295 words/s, in_qsize -1, out_qsize 1\n",
      "2020-08-14 15:34:03,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-14 15:34:03,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-14 15:34:03,873 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-14 15:34:03,874 : INFO : EPOCH - 1 : training on 2066810 raw words (2013916 effective words) took 2.1s, 963366 effective words/s\n",
      "2020-08-14 15:34:05,810 : INFO : EPOCH 2 - PROGRESS: at 37.00% examples, 351610 words/s, in_qsize -1, out_qsize 1\n",
      "2020-08-14 15:34:05,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-14 15:34:05,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-14 15:34:05,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-14 15:34:05,860 : INFO : EPOCH - 2 : training on 2066810 raw words (2014025 effective words) took 2.0s, 1023738 effective words/s\n",
      "2020-08-14 15:34:07,983 : INFO : EPOCH 3 - PROGRESS: at 37.00% examples, 320349 words/s, in_qsize -1, out_qsize 1\n",
      "2020-08-14 15:34:07,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-14 15:34:08,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-14 15:34:08,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-14 15:34:08,032 : INFO : EPOCH - 3 : training on 2066810 raw words (2013894 effective words) took 2.2s, 934830 effective words/s\n",
      "2020-08-14 15:34:10,035 : INFO : EPOCH 4 - PROGRESS: at 32.57% examples, 336701 words/s, in_qsize -1, out_qsize 1\n",
      "2020-08-14 15:34:10,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-14 15:34:10,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-14 15:34:10,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-14 15:34:10,145 : INFO : EPOCH - 4 : training on 2066810 raw words (2013721 effective words) took 2.1s, 963046 effective words/s\n",
      "2020-08-14 15:34:12,340 : INFO : EPOCH 5 - PROGRESS: at 36.81% examples, 308695 words/s, in_qsize -1, out_qsize 1\n",
      "2020-08-14 15:34:12,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-14 15:34:12,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-14 15:34:12,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-14 15:34:12,411 : INFO : EPOCH - 5 : training on 2066810 raw words (2013816 effective words) took 2.2s, 895325 effective words/s\n",
      "2020-08-14 15:34:12,413 : INFO : training on a 10334050 raw words (10069372 effective words) took 10.6s, 945911 effective words/s\n",
      "2020-08-14 15:34:12,414 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x00000206892CC888>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "\n",
    "# Set file names for train and test data\n",
    "corpus_file = open('corpus.txt', encoding='utf-8')\n",
    "\n",
    "model = FT_gensim(size=128)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file='corpus.txt', epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-14 15:36:05,096 : INFO : saving FastText object under ft_0814_0.model, separately None\n",
      "2020-08-14 15:36:05,097 : INFO : storing np array 'vectors_ngrams' to ft_0814_0.model.wv.vectors_ngrams.npy\n",
      "2020-08-14 15:36:09,327 : INFO : not storing attribute vectors_norm\n",
      "2020-08-14 15:36:09,328 : INFO : not storing attribute vectors_vocab_norm\n",
      "2020-08-14 15:36:09,329 : INFO : not storing attribute vectors_ngrams_norm\n",
      "2020-08-14 15:36:09,330 : INFO : not storing attribute buckets_word\n",
      "2020-08-14 15:36:09,331 : INFO : storing np array 'vectors_ngrams_lockf' to ft_0814_0.model.trainables.vectors_ngrams_lockf.npy\n",
      "2020-08-14 15:36:13,527 : INFO : saved ft_0814_0.model\n",
      "2020-08-14 15:36:13,528 : INFO : storing 15061x128 projection weights into ft_0814_0.model\n",
      "2020-08-14 15:36:14,702 : INFO : loading FastText object from ft_0814_0.model\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "could not find MARK",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3426d1940459>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ft_0814_0.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ft_0814_0.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFT_gensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ft_0814_0.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    930\u001b[0m         \"\"\"\n\u001b[0;32m    931\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_vocab_lockf'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \"\"\"\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ns_exponent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \"\"\"\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \u001b[1;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1398\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1399\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: could not find MARK"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "\n",
    "model.save('ft_0814_0.model')\n",
    "model.wv.save_word2vec_format('ft_0814_0.model')\n",
    "model = FT_gensim.load('ft_0814_0.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
