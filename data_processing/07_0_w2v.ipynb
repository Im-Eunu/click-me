{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from eunjeon import Mecab\n",
    "from ast import literal_eval\n",
    "\n",
    "xname = os.path.join(os.path.dirname(os.getcwd()), 'xlsx_data', f\"{'xlsx_#8_clean_text'}.xlsx\")\n",
    "df = pd.read_excel(xname, index_col=0)\n",
    "mecab = Mecab()\n",
    "corpus = ''\n",
    "for i in range(len(df)):\n",
    "    text = literal_eval(df.loc[i, 'text'])\n",
    "    corpus = corpus + ( \"\\n\".join([\" \".join([f for f in mecab.nouns(e) if len(f)>1]) for e in text]))\n",
    "\n",
    "with open('corpus.txt', 'w',encoding='utf-8') as f:\n",
    "    for c in corpus:\n",
    "        f.write(\"%s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 03:25:37,206 : INFO : collecting all words and their counts\n",
      "2020-08-26 03:25:37,212 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-26 03:25:37,256 : INFO : PROGRESS: at sentence #10000, processed 118099 words, keeping 8906 word types\n",
      "2020-08-26 03:25:37,300 : INFO : PROGRESS: at sentence #20000, processed 242590 words, keeping 12354 word types\n",
      "2020-08-26 03:25:37,346 : INFO : PROGRESS: at sentence #30000, processed 365400 words, keeping 15134 word types\n",
      "2020-08-26 03:25:37,390 : INFO : PROGRESS: at sentence #40000, processed 478567 words, keeping 17273 word types\n",
      "2020-08-26 03:25:37,438 : INFO : PROGRESS: at sentence #50000, processed 596532 words, keeping 19428 word types\n",
      "2020-08-26 03:25:37,481 : INFO : PROGRESS: at sentence #60000, processed 715347 words, keeping 21294 word types\n",
      "2020-08-26 03:25:37,523 : INFO : PROGRESS: at sentence #70000, processed 833097 words, keeping 22942 word types\n",
      "2020-08-26 03:25:37,563 : INFO : PROGRESS: at sentence #80000, processed 941361 words, keeping 24530 word types\n",
      "2020-08-26 03:25:37,607 : INFO : PROGRESS: at sentence #90000, processed 1062671 words, keeping 26032 word types\n",
      "2020-08-26 03:25:37,656 : INFO : PROGRESS: at sentence #100000, processed 1195849 words, keeping 27732 word types\n",
      "2020-08-26 03:25:37,702 : INFO : PROGRESS: at sentence #110000, processed 1321860 words, keeping 29263 word types\n",
      "2020-08-26 03:25:37,749 : INFO : PROGRESS: at sentence #120000, processed 1450527 words, keeping 30932 word types\n",
      "2020-08-26 03:25:37,795 : INFO : PROGRESS: at sentence #130000, processed 1574835 words, keeping 32532 word types\n",
      "2020-08-26 03:25:37,846 : INFO : PROGRESS: at sentence #140000, processed 1707740 words, keeping 33880 word types\n",
      "2020-08-26 03:25:37,896 : INFO : PROGRESS: at sentence #150000, processed 1850139 words, keeping 35101 word types\n",
      "2020-08-26 03:25:37,947 : INFO : PROGRESS: at sentence #160000, processed 1999702 words, keeping 36597 word types\n",
      "2020-08-26 03:25:37,991 : INFO : PROGRESS: at sentence #170000, processed 2115398 words, keeping 37665 word types\n",
      "2020-08-26 03:25:38,037 : INFO : PROGRESS: at sentence #180000, processed 2234243 words, keeping 38830 word types\n",
      "2020-08-26 03:25:38,067 : INFO : collected 39723 word types from a corpus of 2319101 raw words and 186559 sentences\n",
      "2020-08-26 03:25:38,067 : INFO : Loading a fresh vocabulary\n",
      "2020-08-26 03:25:38,127 : INFO : effective_min_count=2 retains 25247 unique words (63% of original 39723, drops 14476)\n",
      "2020-08-26 03:25:38,128 : INFO : effective_min_count=2 leaves 2304625 word corpus (99% of original 2319101, drops 14476)\n",
      "2020-08-26 03:25:38,186 : INFO : deleting the raw counts dictionary of 39723 items\n",
      "2020-08-26 03:25:38,187 : INFO : sample=0.001 downsamples 6 most-common words\n",
      "2020-08-26 03:25:38,188 : INFO : downsampling leaves estimated 2286470 word corpus (99.2% of prior 2304625)\n",
      "2020-08-26 03:25:38,204 : INFO : constructing a huffman tree from 25247 words\n",
      "2020-08-26 03:25:38,689 : INFO : built huffman tree with maximum node depth 20\n",
      "2020-08-26 03:25:38,734 : INFO : estimated required memory for 25247 words and 128 dimensions: 56452292 bytes\n",
      "2020-08-26 03:25:38,735 : INFO : resetting layer weights\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "2020-08-26 03:25:42,596 : INFO : training model with 3 workers on 25247 vocabulary and 128 features, using sg=1 hs=1 sample=0.001 negative=5 window=2\n",
      "2020-08-26 03:25:43,603 : INFO : EPOCH 1 - PROGRESS: at 19.08% examples, 422351 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:25:44,612 : INFO : EPOCH 1 - PROGRESS: at 39.78% examples, 430380 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:45,637 : INFO : EPOCH 1 - PROGRESS: at 58.40% examples, 424641 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:46,651 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 417805 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:47,680 : INFO : EPOCH 1 - PROGRESS: at 92.90% examples, 418516 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:47,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 03:25:48,026 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 03:25:48,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 03:25:48,029 : INFO : EPOCH - 1 : training on 2319101 raw words (2286199 effective words) took 5.4s, 421008 effective words/s\n",
      "2020-08-26 03:25:49,037 : INFO : EPOCH 2 - PROGRESS: at 17.66% examples, 392491 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:25:50,042 : INFO : EPOCH 2 - PROGRESS: at 36.87% examples, 401561 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:51,057 : INFO : EPOCH 2 - PROGRESS: at 56.30% examples, 410010 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:25:52,114 : INFO : EPOCH 2 - PROGRESS: at 74.67% examples, 409928 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:53,144 : INFO : EPOCH 2 - PROGRESS: at 91.19% examples, 408278 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:25:53,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 03:25:53,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 03:25:53,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 03:25:53,596 : INFO : EPOCH - 2 : training on 2319101 raw words (2286591 effective words) took 5.6s, 410921 effective words/s\n",
      "2020-08-26 03:25:54,616 : INFO : EPOCH 3 - PROGRESS: at 17.66% examples, 387538 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:55,626 : INFO : EPOCH 3 - PROGRESS: at 39.24% examples, 422378 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:56,645 : INFO : EPOCH 3 - PROGRESS: at 56.30% examples, 407146 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:57,653 : INFO : EPOCH 3 - PROGRESS: at 73.07% examples, 403011 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:25:58,656 : INFO : EPOCH 3 - PROGRESS: at 88.91% examples, 402946 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:25:59,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 03:25:59,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 03:25:59,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 03:25:59,212 : INFO : EPOCH - 3 : training on 2319101 raw words (2286514 effective words) took 5.6s, 407282 effective words/s\n",
      "2020-08-26 03:26:00,227 : INFO : EPOCH 4 - PROGRESS: at 19.60% examples, 428451 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:26:01,252 : INFO : EPOCH 4 - PROGRESS: at 40.80% examples, 434836 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:02,288 : INFO : EPOCH 4 - PROGRESS: at 60.02% examples, 432418 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:03,318 : INFO : EPOCH 4 - PROGRESS: at 79.53% examples, 439112 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:04,335 : INFO : EPOCH 4 - PROGRESS: at 97.08% examples, 432605 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-26 03:26:04,486 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 03:26:04,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 03:26:04,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 03:26:04,524 : INFO : EPOCH - 4 : training on 2319101 raw words (2286512 effective words) took 5.3s, 430561 effective words/s\n",
      "2020-08-26 03:26:05,530 : INFO : EPOCH 5 - PROGRESS: at 17.21% examples, 383129 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:06,541 : INFO : EPOCH 5 - PROGRESS: at 36.10% examples, 391112 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:07,542 : INFO : EPOCH 5 - PROGRESS: at 54.14% examples, 395139 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:08,551 : INFO : EPOCH 5 - PROGRESS: at 69.80% examples, 386400 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:09,587 : INFO : EPOCH 5 - PROGRESS: at 84.50% examples, 383275 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-26 03:26:10,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 03:26:10,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 03:26:10,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 03:26:10,427 : INFO : EPOCH - 5 : training on 2319101 raw words (2286537 effective words) took 5.9s, 387460 effective words/s\n",
      "2020-08-26 03:26:10,428 : INFO : training on a 11595505 raw words (11432353 effective words) took 27.8s, 410776 effective words/s\n",
      "2020-08-26 03:26:10,429 : INFO : storing 25247x128 projection weights into w2v_0825.txt\n",
      "2020-08-26 03:26:12,669 : INFO : saving Word2Vec object under w2v_0825.model, separately None\n",
      "2020-08-26 03:26:12,670 : INFO : not storing attribute vectors_norm\n",
      "2020-08-26 03:26:12,670 : INFO : not storing attribute cum_table\n",
      "2020-08-26 03:26:13,164 : INFO : saved w2v_0825.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models import word2vec\n",
    "from pathlib import Path\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "data = word2vec.LineSentence('corpus.txt')\n",
    "model = word2vec.Word2Vec(size=128, window=2, hs=1, min_count=2, sg=1)\n",
    "model.build_vocab(data)\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    model.train(data, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay\n",
    "\n",
    "model.wv.save_word2vec_format('w2v_0825.txt', binary=False),\n",
    "model.save(\"w2v_0825.model\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 03:26:13,183 : INFO : loading Word2Vec object from w2v_0825.model\n",
      "2020-08-26 03:26:13,539 : INFO : loading wv recursively from w2v_0825.model.wv.* with mmap=None\n",
      "2020-08-26 03:26:13,541 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-08-26 03:26:13,541 : INFO : loading vocabulary recursively from w2v_0825.model.vocabulary.* with mmap=None\n",
      "2020-08-26 03:26:13,542 : INFO : loading trainables recursively from w2v_0825.model.trainables.* with mmap=None\n",
      "2020-08-26 03:26:13,542 : INFO : setting ignored attribute cum_table to None\n",
      "2020-08-26 03:26:13,543 : INFO : loaded w2v_0825.model\n",
      "2020-08-26 03:26:13,623 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진료 - 0.761073\n",
      "진찰 - 0.742590\n",
      "문진 - 0.742022\n",
      "오더 - 0.728113\n",
      "입원 - 0.722342\n",
      "병원 - 0.696627\n",
      "응급 - 0.695246\n",
      "내원 - 0.689098\n",
      "결핵 - 0.689027\n",
      "소아과 - 0.681651\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"w2v_0825.model\")\n",
    "d = model.wv.most_similar(positive=[\"환자\"])\n",
    "for (x, y) in d:\n",
    "    print(\"%s - %f\" % (x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
