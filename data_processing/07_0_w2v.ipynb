{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from eunjeon import Mecab\n",
    "from ast import literal_eval\n",
    "\n",
    "xname = os.path.join(os.path.dirname(os.getcwd()), 'xlsx_data', f\"{'xlsx_#8_clean_text'}.xlsx\")\n",
    "df = pd.read_excel(xname, index_col=0)\n",
    "mecab = Mecab()\n",
    "corpus = ''\n",
    "for i in range(len(df)):\n",
    "    text = literal_eval(df.loc[i, 'text'])\n",
    "    corpus = corpus + ( \"\\n\".join([\" \".join([f for f in mecab.nouns(e) if len(f)>1]) for e in text]))\n",
    "\n",
    "with open('corpus.txt', 'w',encoding='utf-8') as f:\n",
    "    for c in corpus:\n",
    "        f.write(\"%s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 16:28:49,851 : INFO : collecting all words and their counts\n",
      "2020-08-29 16:28:49,857 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-29 16:28:49,894 : INFO : PROGRESS: at sentence #10000, processed 119543 words, keeping 8989 word types\n",
      "2020-08-29 16:28:49,936 : INFO : PROGRESS: at sentence #20000, processed 244375 words, keeping 12414 word types\n",
      "2020-08-29 16:28:49,974 : INFO : PROGRESS: at sentence #30000, processed 367940 words, keeping 15186 word types\n",
      "2020-08-29 16:28:50,012 : INFO : PROGRESS: at sentence #40000, processed 481953 words, keeping 17325 word types\n",
      "2020-08-29 16:28:50,050 : INFO : PROGRESS: at sentence #50000, processed 600054 words, keeping 19501 word types\n",
      "2020-08-29 16:28:50,091 : INFO : PROGRESS: at sentence #60000, processed 719094 words, keeping 21355 word types\n",
      "2020-08-29 16:28:50,129 : INFO : PROGRESS: at sentence #70000, processed 837757 words, keeping 23049 word types\n",
      "2020-08-29 16:28:50,168 : INFO : PROGRESS: at sentence #80000, processed 947711 words, keeping 24617 word types\n",
      "2020-08-29 16:28:50,207 : INFO : PROGRESS: at sentence #90000, processed 1070059 words, keeping 26153 word types\n",
      "2020-08-29 16:28:50,252 : INFO : PROGRESS: at sentence #100000, processed 1204468 words, keeping 27837 word types\n",
      "2020-08-29 16:28:50,294 : INFO : PROGRESS: at sentence #110000, processed 1332760 words, keeping 29544 word types\n",
      "2020-08-29 16:28:50,335 : INFO : PROGRESS: at sentence #120000, processed 1460192 words, keeping 31068 word types\n",
      "2020-08-29 16:28:50,377 : INFO : PROGRESS: at sentence #130000, processed 1589855 words, keeping 32708 word types\n",
      "2020-08-29 16:28:50,423 : INFO : PROGRESS: at sentence #140000, processed 1723240 words, keeping 34046 word types\n",
      "2020-08-29 16:28:50,467 : INFO : PROGRESS: at sentence #150000, processed 1870570 words, keeping 35319 word types\n",
      "2020-08-29 16:28:50,514 : INFO : PROGRESS: at sentence #160000, processed 2014226 words, keeping 36774 word types\n",
      "2020-08-29 16:28:50,551 : INFO : PROGRESS: at sentence #170000, processed 2130530 words, keeping 37825 word types\n",
      "2020-08-29 16:28:50,592 : INFO : PROGRESS: at sentence #180000, processed 2249776 words, keeping 38986 word types\n",
      "2020-08-29 16:28:50,613 : INFO : collected 39717 word types from a corpus of 2314205 raw words and 184907 sentences\n",
      "2020-08-29 16:28:50,613 : INFO : Loading a fresh vocabulary\n",
      "2020-08-29 16:28:50,674 : INFO : effective_min_count=2 retains 25207 unique words (63% of original 39717, drops 14510)\n",
      "2020-08-29 16:28:50,675 : INFO : effective_min_count=2 leaves 2299695 word corpus (99% of original 2314205, drops 14510)\n",
      "2020-08-29 16:28:50,733 : INFO : deleting the raw counts dictionary of 39717 items\n",
      "2020-08-29 16:28:50,735 : INFO : sample=0.001 downsamples 6 most-common words\n",
      "2020-08-29 16:28:50,736 : INFO : downsampling leaves estimated 2281572 word corpus (99.2% of prior 2299695)\n",
      "2020-08-29 16:28:50,759 : INFO : constructing a huffman tree from 25207 words\n",
      "2020-08-29 16:28:51,219 : INFO : built huffman tree with maximum node depth 20\n",
      "2020-08-29 16:28:51,255 : INFO : estimated required memory for 25207 words and 200 dimensions: 78141700 bytes\n",
      "2020-08-29 16:28:51,256 : INFO : resetting layer weights\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "2020-08-29 16:28:54,819 : INFO : training model with 3 workers on 25207 vocabulary and 200 features, using sg=1 hs=1 sample=0.001 negative=5 window=2\n",
      "2020-08-29 16:28:55,831 : INFO : EPOCH 1 - PROGRESS: at 17.24% examples, 381196 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:28:56,849 : INFO : EPOCH 1 - PROGRESS: at 36.22% examples, 388700 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:28:57,860 : INFO : EPOCH 1 - PROGRESS: at 53.84% examples, 389010 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:28:58,881 : INFO : EPOCH 1 - PROGRESS: at 70.59% examples, 388090 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:28:59,899 : INFO : EPOCH 1 - PROGRESS: at 85.23% examples, 385972 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:00,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 16:29:00,690 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 16:29:00,718 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 16:29:00,719 : INFO : EPOCH - 1 : training on 2314205 raw words (2281742 effective words) took 5.9s, 386927 effective words/s\n",
      "2020-08-29 16:29:01,770 : INFO : EPOCH 2 - PROGRESS: at 16.27% examples, 348152 words/s, in_qsize 6, out_qsize 1\n",
      "2020-08-29 16:29:02,780 : INFO : EPOCH 2 - PROGRESS: at 34.77% examples, 368384 words/s, in_qsize 6, out_qsize 1\n",
      "2020-08-29 16:29:03,816 : INFO : EPOCH 2 - PROGRESS: at 53.00% examples, 375530 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:04,822 : INFO : EPOCH 2 - PROGRESS: at 69.51% examples, 376905 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:05,828 : INFO : EPOCH 2 - PROGRESS: at 83.90% examples, 375974 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:06,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 16:29:06,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 16:29:06,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 16:29:06,767 : INFO : EPOCH - 2 : training on 2314205 raw words (2281717 effective words) took 6.0s, 377337 effective words/s\n",
      "2020-08-29 16:29:07,773 : INFO : EPOCH 3 - PROGRESS: at 15.87% examples, 354002 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:08,782 : INFO : EPOCH 3 - PROGRESS: at 33.89% examples, 367285 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:09,797 : INFO : EPOCH 3 - PROGRESS: at 50.81% examples, 367591 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:10,829 : INFO : EPOCH 3 - PROGRESS: at 67.25% examples, 368703 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:11,848 : INFO : EPOCH 3 - PROGRESS: at 81.66% examples, 366500 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:12,868 : INFO : EPOCH 3 - PROGRESS: at 97.66% examples, 364861 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:12,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 16:29:12,983 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 16:29:13,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 16:29:13,004 : INFO : EPOCH - 3 : training on 2314205 raw words (2281585 effective words) took 6.2s, 365958 effective words/s\n",
      "2020-08-29 16:29:14,013 : INFO : EPOCH 4 - PROGRESS: at 16.27% examples, 362435 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:15,053 : INFO : EPOCH 4 - PROGRESS: at 35.80% examples, 380186 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:16,058 : INFO : EPOCH 4 - PROGRESS: at 53.00% examples, 380924 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:17,092 : INFO : EPOCH 4 - PROGRESS: at 70.59% examples, 385541 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:18,130 : INFO : EPOCH 4 - PROGRESS: at 85.23% examples, 382442 words/s, in_qsize 5, out_qsize 1\n",
      "2020-08-29 16:29:18,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 16:29:18,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 16:29:18,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 16:29:18,908 : INFO : EPOCH - 4 : training on 2314205 raw words (2281537 effective words) took 5.9s, 386555 effective words/s\n",
      "2020-08-29 16:29:19,951 : INFO : EPOCH 5 - PROGRESS: at 16.27% examples, 350592 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:20,970 : INFO : EPOCH 5 - PROGRESS: at 34.77% examples, 368356 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:21,999 : INFO : EPOCH 5 - PROGRESS: at 52.15% examples, 369874 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:23,040 : INFO : EPOCH 5 - PROGRESS: at 68.58% examples, 369497 words/s, in_qsize 6, out_qsize 0\n",
      "2020-08-29 16:29:24,042 : INFO : EPOCH 5 - PROGRESS: at 82.69% examples, 368365 words/s, in_qsize 5, out_qsize 0\n",
      "2020-08-29 16:29:25,052 : INFO : EPOCH 5 - PROGRESS: at 98.86% examples, 367117 words/s, in_qsize 3, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 16:29:25,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-29 16:29:25,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-29 16:29:25,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-29 16:29:25,123 : INFO : EPOCH - 5 : training on 2314205 raw words (2281400 effective words) took 6.2s, 367190 effective words/s\n",
      "2020-08-29 16:29:25,124 : INFO : training on a 11571025 raw words (11407981 effective words) took 30.3s, 376444 effective words/s\n",
      "2020-08-29 16:29:25,124 : INFO : storing 25207x200 projection weights into w2v_0829.txt\n",
      "2020-08-29 16:29:28,147 : INFO : saving Word2Vec object under w2v_0829.model, separately None\n",
      "2020-08-29 16:29:28,148 : INFO : not storing attribute vectors_norm\n",
      "2020-08-29 16:29:28,148 : INFO : not storing attribute cum_table\n",
      "2020-08-29 16:29:28,778 : INFO : saved w2v_0829.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models import word2vec\n",
    "from pathlib import Path\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "data = word2vec.LineSentence('corpus.txt')\n",
    "model = word2vec.Word2Vec(size=200, window=2, hs=1, min_count=2, sg=1)\n",
    "model.build_vocab(data)\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    model.train(data, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay\n",
    "\n",
    "model.wv.save_word2vec_format('w2v_0829.txt', binary=False),\n",
    "model.save(\"w2v_0829.model\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 16:30:02,981 : INFO : loading Word2Vec object from w2v_0829.model\n",
      "2020-08-29 16:30:03,467 : INFO : loading wv recursively from w2v_0829.model.wv.* with mmap=None\n",
      "2020-08-29 16:30:03,467 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-08-29 16:30:03,468 : INFO : loading vocabulary recursively from w2v_0829.model.vocabulary.* with mmap=None\n",
      "2020-08-29 16:30:03,469 : INFO : loading trainables recursively from w2v_0829.model.trainables.* with mmap=None\n",
      "2020-08-29 16:30:03,469 : INFO : setting ignored attribute cum_table to None\n",
      "2020-08-29 16:30:03,470 : INFO : loaded w2v_0829.model\n",
      "2020-08-29 16:30:03,530 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응급실 - 0.718561\n",
      "신경외과 - 0.676160\n",
      "진료실 - 0.648930\n",
      "내원 - 0.647565\n",
      "일반외과 - 0.641778\n",
      "외과 - 0.641260\n",
      "복음 - 0.632771\n",
      "강남병원 - 0.630099\n",
      "안암 - 0.628555\n",
      "초진 - 0.627105\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"w2v_0829.model\")\n",
    "d = model.wv.most_similar(positive=[\"병원\"])\n",
    "for (x, y) in d:\n",
    "    print(\"%s - %f\" % (x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0829 space-correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
